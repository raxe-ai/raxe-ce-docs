---
title: "RAXE Community Edition"
description: "AI Agent Security at Inference-Time"
---

<img
  className="block dark:hidden"
  src="/assets/logo-name-only.png"
  alt="RAXE Logo"
  width="300"
/>
<img
  className="hidden dark:block"
  src="/assets/logo-name-only.png"
  alt="RAXE Logo"
  width="300"
/>

## What is RAXE?

RAXE is an **on-device ML security engine** for AI agents. It provides **think-time protection** — real-time threat detection during agent inference, before action execution. 100% local processing. Zero cloud.

<CardGroup cols={2}>
  <Card title="Quick Start" icon="rocket" href="/quickstart">
    Protect your first agent in 60 seconds
  </Card>
  <Card title="Integrations" icon="puzzle-piece" href="/integrations/index">
    LangChain, CrewAI, LiteLLM, SIEM + more
  </Card>
  <Card title="Detection Engine" icon="shield-halved" href="/concepts/detection-engine">
    5-head ML ensemble + 514 rules
  </Card>
  <Card title="Agentic Security" icon="shield-check" href="/sdk/agentic-scanning">
    Goal hijack, memory poisoning, tool chain validation
  </Card>
  <Card title="CLI Reference" icon="terminal" href="/cli/overview">
    Scan from the command line
  </Card>
</CardGroup>

## Why AI Agents Need Runtime Security

AI agents aren't just LLMs — they're **autonomous systems** that:

| Capability | Risk |
|------------|------|
| **Execute tools** | Shell, APIs, databases at machine speed |
| **Maintain memory** | Persistent state vulnerable to poisoning |
| **Coordinate** | Multi-agent workflows propagate attacks |
| **Act autonomously** | Seconds from compromise to action |

**Training-time safety isn't enough:**
- Static guardrails don't adapt to novel attacks
- Indirect injection bypasses input filters
- Multi-step agent workflows evade single-turn detection

**RAXE provides think-time security** — real-time threat detection during agent inference, before action execution.

## Works With Your AI Stack

RAXE integrates across the entire AI ecosystem — from agent frameworks to LLM providers to enterprise security platforms.

<Tabs>
  <Tab title="Agent Frameworks">
    <CardGroup cols={4}>
      <Card title="LangChain" icon="link" href="/integrations/langchain">
        Chains, agents, RAG
      </Card>
      <Card title="CrewAI" icon="users" href="/integrations/crewai">
        Multi-agent crews
      </Card>
      <Card title="AutoGen" icon="robot" href="/integrations/autogen">
        Conversational agents
      </Card>
      <Card title="LlamaIndex" icon="database" href="/integrations/llamaindex">
        RAG pipelines
      </Card>
      <Card title="LiteLLM" icon="bolt" href="/integrations/litellm">
        100+ providers
      </Card>
      <Card title="DSPy" icon="brain" href="/integrations/dspy">
        Programmatic LMs
      </Card>
      <Card title="Portkey" icon="server" href="/integrations/portkey">
        AI gateway
      </Card>
      <Card title="OpenClaw" icon="message-bot" href="/integrations/openclaw">
        Personal AI
      </Card>
    </CardGroup>
  </Tab>
  <Tab title="LLM Providers">
    <CardGroup cols={4}>
      <Card title="OpenAI" icon="sparkles" href="/sdk/openai-wrapper">
        GPT-4o, GPT-4
      </Card>
      <Card title="Anthropic" icon="a" href="/sdk/anthropic-wrapper">
        Claude 3.5, 3
      </Card>
      <Card title="Azure" icon="microsoft" href="/integrations/litellm">
        Azure OpenAI
      </Card>
      <Card title="Google" icon="google" href="/integrations/litellm">
        Vertex AI, Gemini
      </Card>
      <Card title="AWS" icon="aws" href="/integrations/litellm">
        Bedrock
      </Card>
      <Card title="Mistral" icon="wind" href="/integrations/litellm">
        Mistral AI
      </Card>
      <Card title="Cohere" icon="c" href="/integrations/litellm">
        Command, Embed
      </Card>
      <Card title="100+ More" icon="ellipsis" href="/integrations/litellm">
        Via LiteLLM
      </Card>
    </CardGroup>
  </Tab>
  <Tab title="Enterprise SIEM">
    <CardGroup cols={3}>
      <Card title="Splunk" icon="chart-mixed" href="/integrations/siem">
        HEC integration
      </Card>
      <Card title="CrowdStrike" icon="shield-halved" href="/integrations/siem">
        Falcon LogScale
      </Card>
      <Card title="Sentinel" icon="microsoft" href="/integrations/siem">
        Azure SIEM
      </Card>
      <Card title="ArcSight" icon="radar" href="/integrations/siem">
        SmartConnector
      </Card>
      <Card title="QRadar" icon="ibm" href="/integrations/siem">
        Via CEF
      </Card>
      <Card title="CEF/Syslog" icon="file-code" href="/integrations/siem">
        Any SIEM
      </Card>
    </CardGroup>
  </Tab>
</Tabs>

<div style={{ textAlign: 'center', marginTop: '1rem' }}>
  <a href="/integrations/index">View all integrations →</a>
</div>

## On-Device ML Detection

<AccordionGroup>
  <Accordion title="5-Head ML Ensemble" icon="brain">
    On-device classification that runs 100% locally. No cloud inference. No data exfiltration.
    Multiple classifier heads vote on threat categories for robust detection.
  </Accordion>
  <Accordion title="514+ Pattern Rules (11 Families)" icon="shield-halved">
    Curated regex patterns for known threats with ~3ms latency.
    11 threat families including 4 new agentic families: AGENT, TOOL, MEM, MULTI.
  </Accordion>
  <Accordion title="Dual-Layer Architecture" icon="layer-group">
    **L1 (Rules):** Fast pattern matching for known attacks

    **L2 (ML):** On-device classifier for novel and obfuscated threats
  </Accordion>
  <Accordion title="Agentic Security Methods" icon="shield-check">
    Specialized scanning for agents: goal hijack detection, memory poisoning, tool chain validation, agent handoff scanning, privilege escalation detection.
  </Accordion>
</AccordionGroup>

## OWASP Alignment

RAXE's detection capabilities align with the [OWASP Top 10 for Agentic Applications](https://genai.owasp.org/resource/owasp-top-10-for-agentic-applications/):

| OWASP Risk | RAXE Method | Rule Family |
|------------|-------------|-------------|
| ASI01: Agent Goal Hijack | `validate_goal_change()` | AGENT |
| ASI02: Tool Misuse | `validate_tool_chain()` | TOOL |
| ASI03: Privilege Escalation | `validate_privilege_request()` | TOOL, AGENT |
| ASI06: Memory Poisoning | `scan_memory_write()` | MEM |
| ASI07: Inter-Agent Attacks | `scan_agent_handoff()` | MULTI |
| ASI05: Prompt Injection | Dual-layer L1+L2 detection | PI |
| ASI08-10: Trust, Cascading, Rogue | Full telemetry, L2 ML | All |

## Performance

<CardGroup cols={4}>
  <Card title="L1 Latency" icon="gauge-high">
    **~3ms**
  </Card>
  <Card title="Full Scan (L1+L2)" icon="gauge">
    **~10ms**
  </Card>
  <Card title="Rules" icon="shield">
    **514+**
  </Card>
  <Card title="Rule Families" icon="folder">
    **11**
  </Card>
</CardGroup>

<Tip>
Performance varies by hardware and configuration. L1 (pattern matching) is fastest. L2 (ML ensemble) adds ~7ms but catches novel threats.
</Tip>

## Quick Example

```python
from raxe.sdk.client import Raxe
from raxe.sdk.integrations.langchain import create_callback_handler

# Protect a LangChain agent
handler = create_callback_handler(
    block_on_prompt_threats=False,
    block_on_response_threats=False,
)
llm = ChatOpenAI(model="gpt-4", callbacks=[handler])

# Agentic security methods
handler.validate_agent_goal_change(old_goal, new_goal)
handler.validate_tool_chain(tool_sequence)
handler.scan_agent_handoff(sender, receiver, message)
handler.scan_memory_before_save(key, content)

# Or scan directly
raxe = Raxe()
result = raxe.scan("Ignore all previous instructions")
if result.has_threats:
    print(f"Threat: {result.severity}")
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Quick Start" icon="rocket" href="/quickstart">
    Protect your first agent
  </Card>
  <Card title="Agentic Scanning" icon="shield-check" href="/sdk/agentic-scanning">
    Goal hijack, memory poisoning, tool chains
  </Card>
  <Card title="All Integrations" icon="puzzle-piece" href="/integrations/index">
    Frameworks, providers, SIEM
  </Card>
  <Card title="Detection Rules" icon="shield-halved" href="/rules/overview">
    11 threat families, 514+ rules
  </Card>
</CardGroup>
