---
title: "RAXE Community Edition"
description: "AI Agent Security at Inference-Time"
---

<img
  className="block dark:hidden"
  src="/assets/logo-name-only.png"
  alt="RAXE Logo"
  width="300"
/>
<img
  className="hidden dark:block"
  src="/assets/logo-name-only.png"
  alt="RAXE Logo"
  width="300"
/>

## What is RAXE?

RAXE is an **on-device ML security engine** for AI agents. It provides **think-time protection** — real-time threat detection during agent inference, before action execution. 100% local processing. Zero cloud.

<CardGroup cols={2}>
  <Card title="Quick Start" icon="rocket" href="/quickstart">
    Protect your first agent in 60 seconds
  </Card>
  <Card title="Agent Frameworks" icon="robot" href="/integrations/langchain">
    LangChain, CrewAI, AutoGen, LlamaIndex + more
  </Card>
  <Card title="Detection Engine" icon="shield-halved" href="/concepts/detection-engine">
    5-head ML ensemble + 514 rules
  </Card>
  <Card title="Agentic Security" icon="shield-check" href="/sdk/agentic-scanning">
    Goal hijack, memory poisoning, tool chain validation
  </Card>
  <Card title="CLI Reference" icon="terminal" href="/cli/overview">
    Scan from the command line
  </Card>
</CardGroup>

## Why AI Agents Need Runtime Security

AI agents aren't just LLMs — they're **autonomous systems** that:

| Capability | Risk |
|------------|------|
| **Execute tools** | Shell, APIs, databases at machine speed |
| **Maintain memory** | Persistent state vulnerable to poisoning |
| **Coordinate** | Multi-agent workflows propagate attacks |
| **Act autonomously** | Seconds from compromise to action |

**Training-time safety isn't enough:**
- Static guardrails don't adapt to novel attacks
- Indirect injection bypasses input filters
- Multi-step agent workflows evade single-turn detection

**RAXE provides think-time security** — real-time threat detection during agent inference, before action execution.

## Agent Framework Support

RAXE integrates natively with leading agent frameworks:

| Framework | Handler | What RAXE Protects |
|-----------|---------|-------------------|
| [LangChain](/integrations/langchain) | `RaxeCallbackHandler` | Chains, agents, tools, memory |
| [CrewAI](/integrations/crewai) | `RaxeCrewGuard` | Multi-agent crews, task handoffs |
| [AutoGen](/integrations/autogen) | `RaxeConversationGuard` | Conversational agents, functions |
| [LlamaIndex](/integrations/llamaindex) | `RaxeAgentCallback` | ReAct agents, RAG retrieval |
| [LiteLLM](/integrations/litellm) | `RaxeLiteLLMCallback` | 100+ LLM providers |
| [DSPy](/integrations/dspy) | `RaxeDSPyCallback` | Programmatic modules |
| [Portkey](/integrations/portkey) | `RaxePortkeyGuard` | AI gateway traffic |

## On-Device ML Detection

<AccordionGroup>
  <Accordion title="5-Head ML Ensemble" icon="brain">
    On-device classification that runs 100% locally. No cloud inference. No data exfiltration.
    Multiple classifier heads vote on threat categories for robust detection.
  </Accordion>
  <Accordion title="514+ Pattern Rules (11 Families)" icon="shield-halved">
    Curated regex patterns for known threats with ~3ms latency.
    11 threat families including 4 new agentic families: AGENT, TOOL, MEM, MULTI.
  </Accordion>
  <Accordion title="Dual-Layer Architecture" icon="layer-group">
    **L1 (Rules):** Fast pattern matching for known attacks

    **L2 (ML):** On-device classifier for novel and obfuscated threats
  </Accordion>
  <Accordion title="Agentic Security Methods" icon="shield-check">
    Specialized scanning for agents: goal hijack detection, memory poisoning, tool chain validation, agent handoff scanning, privilege escalation detection.
  </Accordion>
</AccordionGroup>

## OWASP Alignment

RAXE's detection capabilities align with the [OWASP Top 10 for Agentic Applications](https://genai.owasp.org/resource/owasp-top-10-for-agentic-applications/):

| OWASP Risk | RAXE Method | Rule Family |
|------------|-------------|-------------|
| ASI01: Agent Goal Hijack | `validate_goal_change()` | AGENT |
| ASI02: Tool Misuse | `validate_tool_chain()` | TOOL |
| ASI03: Privilege Escalation | `validate_privilege_request()` | TOOL, AGENT |
| ASI06: Memory Poisoning | `scan_memory_write()` | MEM |
| ASI07: Inter-Agent Attacks | `scan_agent_handoff()` | MULTI |
| ASI05: Prompt Injection | Dual-layer L1+L2 detection | PI |
| ASI08-10: Trust, Cascading, Rogue | Full telemetry, L2 ML | All |

## Performance

<CardGroup cols={4}>
  <Card title="L1 Latency" icon="gauge-high">
    **~3ms**
  </Card>
  <Card title="Full Scan (L1+L2)" icon="gauge">
    **~10ms**
  </Card>
  <Card title="Rules" icon="shield">
    **514+**
  </Card>
  <Card title="Rule Families" icon="folder">
    **11**
  </Card>
</CardGroup>

<Tip>
Performance varies by hardware and configuration. L1 (pattern matching) is fastest. L2 (ML ensemble) adds ~7ms but catches novel threats.
</Tip>

## Quick Example

```python
from raxe.sdk.client import Raxe
from raxe.sdk.integrations.langchain import create_callback_handler

# Protect a LangChain agent
handler = create_callback_handler(
    block_on_prompt_threats=False,
    block_on_response_threats=False,
)
llm = ChatOpenAI(model="gpt-4", callbacks=[handler])

# Agentic security methods
handler.validate_agent_goal_change(old_goal, new_goal)
handler.validate_tool_chain(tool_sequence)
handler.scan_agent_handoff(sender, receiver, message)
handler.scan_memory_before_save(key, content)

# Or scan directly
raxe = Raxe()
result = raxe.scan("Ignore all previous instructions")
if result.has_threats:
    print(f"Threat: {result.severity}")
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Quick Start" icon="rocket" href="/quickstart">
    Protect your first agent
  </Card>
  <Card title="Agentic Scanning" icon="shield-check" href="/sdk/agentic-scanning">
    Goal hijack, memory poisoning, tool chains
  </Card>
  <Card title="Agent Frameworks" icon="robot" href="/integrations/langchain">
    LangChain, CrewAI, AutoGen + more
  </Card>
  <Card title="Detection Rules" icon="shield-halved" href="/rules/overview">
    11 threat families, 514+ rules
  </Card>
</CardGroup>
